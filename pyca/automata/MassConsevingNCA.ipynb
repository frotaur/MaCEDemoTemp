{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import cv2\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "from modules.models.utils import torch_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504f00c17b99b6fa",
   "metadata": {},
   "source": [
    "# Define Image Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16445fdcb58755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_IMAGE = \"./Images/lizard.png\" #<--- image to grow\n",
    "IMAGE_NAME = \"Lizard\" #<--- name of image for saving purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c262e2937641d74f",
   "metadata": {},
   "source": [
    "# Choose Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22651b8ef4ff62d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:0\" #<--- if no GPU change to \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de96acedb48fe7f",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c902d9c20cf1f84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "HEIGHT = 50\n",
    "WIDTH = 50\n",
    "CHANNELS = 16 #<--- NCA feature channels\n",
    "BATCH_SIZE = 16\n",
    "HIDDEN_DIM = 64\n",
    "MASKING = 0\n",
    "POOL_SIZE = 256 #<--- NCA training pool size, lower values train faster but are less stable\n",
    "TRAINING_ITERS = 14000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528aa9f2ad130c5d",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37374b8cdb99d683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perchannel_conv(x, filters):\n",
    "    b, ch, h, w = x.shape\n",
    "    y = x.reshape(b * ch, 1, h, w)\n",
    "    y = torch.nn.functional.pad(y, [1, 1, 1, 1], 'circular')\n",
    "    y = torch.nn.functional.conv2d(y, filters[:, None])\n",
    "    return y.reshape(b, -1, h, w)\n",
    "\n",
    "ident = torch.tensor([[0.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 0.0]], dtype=torch.float32, device=DEVICE)\n",
    "ones = torch.tensor([[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, 1.0]], dtype=torch.float32, device=DEVICE)\n",
    "sobel_x = torch.tensor([[-1.0, 0.0, 1.0], [-2.0, 0.0, 2.0], [-1.0, 0.0, 1.0]], dtype=torch.float32, device=DEVICE)\n",
    "lap = torch.tensor([[1.0, 2.0, 1.0], [2.0, -12, 2.0], [1.0, 2.0, 1.0]], dtype=torch.float32, device=DEVICE)\n",
    "gaus = torch.tensor([[1.0, 2.0, 1.0], [2.0, 4.0, 2.0], [1.0, 2.0, 1.0]], dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "def perception(x):\n",
    "    filters = torch.stack([sobel_x, sobel_x.T, lap])\n",
    "    obs = perchannel_conv(x, filters)\n",
    "    return torch.cat((x,obs), dim = 1 )\n",
    "\n",
    "\n",
    "class MassConservingNCA(torch.nn.Module):\n",
    "    def __init__(self,C,hidden_n, device):\n",
    "        super(MassConservingNCA, self).__init__()\n",
    "        self.C = C\n",
    "        self.w1 = torch.nn.Conv2d(4 * C, hidden_n, 1)\n",
    "        self.w2 = torch.nn.Conv2d(hidden_n, C, 1, bias=False)\n",
    "        self.w2.weight.data.zero_()\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, x, update_rate=1):\n",
    "        y = perception(x)\n",
    "        y = self.w2(torch.relu(self.w1(y)))\n",
    "        b, c, h, w = y.shape\n",
    "        update_mask = (torch.rand(b, 1, h, w, device=self.device) + update_rate).floor()\n",
    "\n",
    "        x_normal = x[:,3:,...]\n",
    "        x_mass = x[:,:3,...]\n",
    "\n",
    "        y_normal = y[:,3:,...]\n",
    "        y_mass = y[:,:3,...]\n",
    "\n",
    "        Aff = torch.exp(y_mass*0.1)\n",
    "\n",
    "        x_mass = self.redistribution(Aff, x_mass)\n",
    "        x_normal = x_normal + y_normal * update_mask\n",
    "\n",
    "        x = torch.cat((x_mass, x_normal), dim = 1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def redistribution(self,Aff,state):\n",
    "\n",
    "        B, C, H, W = state.shape\n",
    "        Aff_exp = F.pad(Aff, (1, 1, 1, 1, 1, 1), mode=\"circular\")  # (B,C,H+2,W+2) for the (3,3) kernel\n",
    "        Aff_exp = torch_utils.unfold3d(Aff_exp, kernel_size=(3, 3, 3)).reshape(B, C, 27, H, W)  # (B,C*9,H,W)\n",
    "        E = Aff_exp.sum(dim=2)\n",
    "        E_exp = F.pad(E, (1, 1, 1, 1, 1, 1), mode=\"circular\")\n",
    "        E_exp = torch_utils.unfold3d(E_exp, kernel_size=(3, 3, 3)).reshape(B, C, 27, H, W)  # (B,C*9,H,W)\n",
    "        state_exp = F.pad(state, (1, 1, 1, 1, 1, 1), mode=\"circular\")\n",
    "        state_exp = torch_utils.unfold3d(state_exp, kernel_size=(3, 3, 3)).reshape(B, C, 27, H, W)  # (B,C*9,H,W)\n",
    "\n",
    "        state = ((Aff[:, :, None, ...] / E_exp) * state_exp).sum(dim=2)\n",
    "\n",
    "        return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c11ca9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2db62445a20fcca8",
   "metadata": {},
   "source": [
    "# Utililities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac2d8bc749f1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(results, channels=4):\n",
    "    x = results.cpu().clone().permute((0, 2, 3, 1)).detach().numpy()\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    num = results.shape[0]\n",
    "    if num > 8:\n",
    "        num = 8\n",
    "    for i in range(num):\n",
    "        img = x[i, :, :, 0:channels]\n",
    "        plt.figure(2)\n",
    "        plt.subplot(2, 4, i + 1)\n",
    "        plt.imshow(img)\n",
    "\n",
    "\n",
    "def get_batch(pool, x_prime, batch_size):\n",
    "    idxs = np.random.randint(0, pool.shape[0], batch_size)\n",
    "    batch = pool[idxs, :, :, :]\n",
    "    batch[0:2, :, :, :] = x_prime\n",
    "    return batch, idxs\n",
    "\n",
    "\n",
    "def update_pool(pool, results, idxs):\n",
    "    pool[idxs] = results.clone().detach()\n",
    "    return pool\n",
    "\n",
    "\n",
    "def get_image(path,height=50, width=50, padding =0):\n",
    "    base = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    base = cv2.resize(base, (int(height), int(width)), interpolation=cv2.INTER_LINEAR)\n",
    "    base_2 = base / 255\n",
    "    base_2[..., :3] *= base_2[..., 3:]\n",
    "    base_torch = torch.tensor(base_2, dtype=torch.float32, requires_grad=True).permute((2, 0, 1)).to(DEVICE)\n",
    "    base_torch = torch.nn.functional.pad(base_torch, [padding,padding,padding,padding ])\n",
    "    base_tt = base_torch.cpu().permute((1, 2, 0)).clone().detach().numpy()\n",
    "    return base_torch,base_tt\n",
    "\n",
    "def get_reference_image_and_seed(path, height = 50, width =50, channels =16):\n",
    "    base = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    base = cv2.resize(base, (int(height), int(width)), interpolation=cv2.INTER_LINEAR)\n",
    "    base_2 = base / 255\n",
    "    base_2[..., :3] *= base_2[..., 3:]\n",
    "    base_torch = torch.tensor(base_2, dtype=torch.float32, requires_grad=True).permute((2, 0, 1)).to(DEVICE)\n",
    "    x_prime = torch.zeros((channels, height, width), dtype=torch.float32).to(DEVICE)\n",
    "    x_prime[:3, int(height / 2), int(width / 2)] = base_torch[:3].sum()/3\n",
    "    return base_torch, x_prime\n",
    "\n",
    "def to_vue_image(tensor):\n",
    "    return tensor.cpu().permute((1, 2, 0)).clone().detach().numpy()\n",
    "\n",
    "def double_mass(state, max):\n",
    "    B, C, H, W = state.shape\n",
    "    n_state = [state[i,:3].clone() *2 if (state[i,:3].sum() *2) < max else state[i,:3] for i in range(B)]\n",
    "    n_state = torch.stack(n_state, dim=0)\n",
    "\n",
    "    return torch.cat((n_state, state[:,3:]), dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594506eb857c31d1",
   "metadata": {},
   "source": [
    "# Get reference image and seed cell based on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24ebe9c72822776",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_image,seed = get_reference_image_and_seed(PATH_TO_IMAGE, HEIGHT,WIDTH,CHANNELS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befe22b866b396b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(3)\n",
    "plt.imshow(to_vue_image(reference_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af326dd774f3b6fa",
   "metadata": {},
   "source": [
    "# Instantiate Pool and MaCENCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d51ae31aad9e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = torch.tile(seed, (POOL_SIZE, 1, 1, 1))\n",
    "loss_log = []\n",
    "nca = MassConservingNCA(CHANNELS,HIDDEN_DIM, device=DEVICE)\n",
    "nca = nca.to(DEVICE)\n",
    "optim = torch.optim.AdamW(nca.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=3000, gamma=0.3)\n",
    "save_dir = IMAGE_NAME + \"_\"+ \"Growing.pth\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10f8668377ce17a",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fcd06660a57e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(TRAINING_ITERS + 1):\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        x, idxs = get_batch(pool, seed, BATCH_SIZE)\n",
    "\n",
    "    for j in range(random.randint(32,64)):\n",
    "        #if ((j%5) == 0) and (j > 0):\n",
    "            #with torch.no_grad():\n",
    "                #x = double_mass(x, mass)\n",
    "        x = nca(x)\n",
    "\n",
    "    loss = (reference_image[None,...] - x[:, :4, :, :]).pow(2).sum()\n",
    "    with torch.no_grad():\n",
    "        loss.backward()\n",
    "        for p in nca.parameters():\n",
    "            p.grad /= (p.grad.norm() + 1e-8)\n",
    "        optim.step()\n",
    "        x = x.detach()\n",
    "        optim.zero_grad()\n",
    "\n",
    "    loss_log.append(loss.log().item())\n",
    "    pool = update_pool(pool, x.clone().detach(), idxs)\n",
    "    scheduler.step()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        clear_output()\n",
    "        print(f\"Training itter {i}, loss = {loss.item()}\")\n",
    "        plt.clf()\n",
    "\n",
    "        plt.figure(1,figsize=(10, 4))\n",
    "        plt.title('Loss history')\n",
    "\n",
    "        plt.plot(loss_log, '.', alpha=0.5, color = \"b\")\n",
    "        show_batch(x)\n",
    "        plt.show(block=False)\n",
    "        plt.pause(0.01)\n",
    "    if i % 100 == 0:\n",
    "        torch.save(nca.state_dict(),  save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adb1b4b24f4185f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
